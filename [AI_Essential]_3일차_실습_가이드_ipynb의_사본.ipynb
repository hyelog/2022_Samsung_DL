{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyelog/2022_Samsung_DL/blob/main/%5BAI_Essential%5D_3%EC%9D%BC%EC%B0%A8_%EC%8B%A4%EC%8A%B5_%EA%B0%80%EC%9D%B4%EB%93%9C_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c265e6e4",
      "metadata": {
        "id": "c265e6e4"
      },
      "source": [
        "# 05. 합성곱신경망 (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6ad381d",
      "metadata": {
        "id": "e6ad381d"
      },
      "source": [
        "## 05-001 2D 컨볼루션 출력 크기 계산 함수 구현\n",
        "- 이 실습에서는 2D 컨볼루션 레이어의 출력 크기를 계산하는 함수를 구현합니다. 입력 크기, 커널 크기, 스트라이드, 패딩을 매개변수로 받아 컨볼루션 계산 공식을 사용하여 출력 높이와 너비를 반환합니다. 이 함수는 CNN 모델 설계 시 출력 크기를 예측하는 데 유용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58fb9b7a",
      "metadata": {
        "id": "58fb9b7a"
      },
      "outputs": [],
      "source": [
        "def conv2d_output_size(input_size, kernel_size, stride=1, padding=0):\n",
        "    height, width = input_size\n",
        "\n",
        "    # Convolution 공식 적용\n",
        "    out_height = (height + 2 * padding - kernel_size) // stride + 1\n",
        "    out_width = (width + 2 * padding - kernel_size) // stride + 1\n",
        "\n",
        "    return out_height, out_width"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89eeee03",
      "metadata": {
        "id": "89eeee03"
      },
      "source": [
        "- 2D 컨볼루션의 출력 크기를 계산하는 함수를 구현하는 과정을 실습합니다. 이 함수는 신경망 설계 시 중요한 역할을 합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c609669c",
      "metadata": {
        "id": "c609669c"
      },
      "source": [
        "## 05-002 컨볼루션 출력 크기 계산\n",
        "- 이 실습에서는 앞서 구현한 conv2d_output_size() 함수를 사용하여 컨볼루션 레이어의 출력 크기를 계산합니다. 입력으로 28x28 크기의 이미지와 3x3 커널, 스트라이드 1, 패딩 0을 설정하여 출력 feature map의 크기를 확인합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f18df361",
      "metadata": {
        "id": "f18df361"
      },
      "outputs": [],
      "source": [
        "# 입력 크기 (Height, Width), 커널 크기, 스트라이드, 패딩\n",
        "output_size = conv2d_output_size((28, 28), 3, 1, 0)\n",
        "print(f\"Output feature map size: {output_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "468918c3",
      "metadata": {
        "id": "468918c3"
      },
      "source": [
        "- 입력 이미지와 커널의 크기를 사용하여 컨볼루션의 출력 크기를 계산하고 확인하는 과정을 실습합니다. 이를 통해 CNN 모델의 구조를 이해하는 데 도움이 됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9cde762",
      "metadata": {
        "id": "a9cde762"
      },
      "source": [
        "## 05-003 패딩을 포함한 컨볼루션 출력 크기 계산\n",
        "- 이 실습에서는 conv2d_output_size() 함수를 사용하여 패딩을 포함한 컨볼루션 레이어의 출력 크기를 계산합니다. 입력으로 28x28 크기의 이미지와 3x3 커널, 스트라이드 1, 패딩 1을 설정하여 출력 feature map의 크기를 확인합니다. 이 과정은 CNN 설계 시 출력 크기를 예측하는 데 중요합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90c0f186",
      "metadata": {
        "id": "90c0f186"
      },
      "outputs": [],
      "source": [
        "# 입력 크기 (Height, Width), 커널 크기, 스트라이드, 패딩\n",
        "output_size = conv2d_output_size((28, 28), 3, 1, 1)\n",
        "print(f\"Output feature map size: {output_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eae1d2ff",
      "metadata": {
        "id": "eae1d2ff"
      },
      "source": [
        "- 패딩을 포함하여 컨볼루션의 출력 크기를 계산하고 확인하는 과정을 실습합니다. 패딩의 효과를 이해하는 데 도움이 됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98b77064",
      "metadata": {
        "id": "98b77064"
      },
      "source": [
        "## 05-004 스트라이드를 포함한 컨볼루션 출력 크기 계산\n",
        "- 이 실습에서는 conv2d_output_size() 함수를 사용하여 스트라이드를 포함한 컨볼루션 레이어의 출력 크기를 계산합니다. 입력으로 28x28 크기의 이미지와 3x3 커널, 스트라이드 2, 패딩 0을 설정하여 출력 feature map의 크기를 확인합니다. 이 과정은 CNN 모델 설계 시 중요한 요소입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbdfdee1",
      "metadata": {
        "id": "dbdfdee1"
      },
      "outputs": [],
      "source": [
        "# 입력 크기 (Height, Width), 커널 크기, 스트라이드, 패딩\n",
        "output_size = conv2d_output_size((28, 28), 3, 2, 0)\n",
        "print(f\"Output feature map size: {output_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "632f521e",
      "metadata": {
        "id": "632f521e"
      },
      "source": [
        "- 스트라이드를 포함하여 컨볼루션의 출력 크기를 계산하고 확인하는 과정을 실습합니다. 스트라이드의 효과를 이해하는 데 도움이 됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "036e69db",
      "metadata": {
        "id": "036e69db"
      },
      "source": [
        "## 05-005 스트라이드 및 패딩을 포함한 컨볼루션 출력 크기 계산\n",
        "- 이 실습에서는 conv2d_output_size() 함수를 사용하여 스트라이드와 패딩을 모두 포함한 컨볼루션 레이어의 출력 크기를 계산합니다. 입력으로 28x28 크기의 이미지와 3x3 커널, 스트라이드 2, 패딩 1을 설정하여 출력 feature map의 크기를 확인합니다. 이 과정은 CNN 설계 시 중요한 요소입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbf59c65",
      "metadata": {
        "id": "cbf59c65"
      },
      "outputs": [],
      "source": [
        "# 입력 크기 (Height, Width), 커널 크기, 스트라이드, 패딩\n",
        "output_size = conv2d_output_size((28, 28), 3, 2, 1)\n",
        "print(f\"Output feature map size: {output_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e73e229",
      "metadata": {
        "id": "4e73e229"
      },
      "source": [
        "- 스트라이드와 패딩을 포함하여 컨볼루션의 출력 크기를 계산하고 확인하는 과정을 실습합니다. 이를 통해 CNN의 동작을 더 깊이 이해할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb270c7f",
      "metadata": {
        "id": "eb270c7f"
      },
      "source": [
        "## 05-006 PyTorch 및 관련 모듈 임포트와 device 설정\n",
        "- 이 실습에서는 PyTorch와 관련된 모듈을 임포트하고, 신경망을 GPU 또는 CPU에서 실행할 수 있도록 device를 설정하는 방법을 학습합니다. torch.device()를 사용하여 GPU 사용 가능 여부에 따라 적절한 장치를 선택합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8886a1e2",
      "metadata": {
        "id": "8886a1e2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install JAEN -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43d3937d",
      "metadata": {
        "id": "43d3937d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f12e160-8341-4800-a2ea-b739b430a9fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchinfo import summary\n",
        "from JAEN.utils import plot_training_results\n",
        "\n",
        "# device 설정 (GPU가 사용 가능하면 GPU로, 그렇지 않으면 CPU 사용)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f13f389",
      "metadata": {
        "id": "3f13f389"
      },
      "source": [
        "- PyTorch의 다양한 모듈을 임포트하고, 학습에 사용할 장치(GPU 또는 CPU)를 설정하는 과정을 실습합니다. 이를 통해 GPU 가속을 활용한 빠른 연산이 가능해집니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4747f1a2",
      "metadata": {
        "id": "4747f1a2"
      },
      "source": [
        "## 05-007 FashionMNIST 데이터 변환 및 정규화\n",
        "- 이 실습에서는 FashionMNIST 데이터를 신경망에 입력할 수 있도록 텐서로 변환하고, 데이터를 정규화하는 방법을 학습합니다. transforms.ToTensor()는 이미지를 텐서로 변환하고, transforms.Normalize()는 평균과 표준편차를 이용해 데이터를 정규화하여 모델 학습 시 안정성을 높입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "065525d9",
      "metadata": {
        "id": "065525d9"
      },
      "outputs": [],
      "source": [
        "# FashionMNIST 데이터 변환 (이미지를 텐서로 변환하고 [0, 1] 범위로 정규화)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "335d166e",
      "metadata": {
        "id": "335d166e"
      },
      "source": [
        "- FashionMNIST 데이터를 텐서로 변환하고, 정규화를 적용하는 과정을 실습합니다. 데이터 정규화는 모델의 학습 성능을 향상시키는 중요한 전처리 과정입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5a800e5",
      "metadata": {
        "id": "f5a800e5"
      },
      "source": [
        "## 05-008 FashionMNIST 학습 및 테스트 데이터셋 로드\n",
        "- 이 실습에서는 FashionMNIST 데이터셋을 학습용과 테스트용으로 로드하는 방법을 학습합니다. train=True로 설정된 데이터셋은 학습용 데이터로, train=False로 설정된 데이터셋은 테스트용 데이터로 로드됩니다. transform을 통해 앞서 정의한 이미지 변환 및 정규화가 적용됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1d30427",
      "metadata": {
        "id": "a1d30427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32fce730-5d64-40b5-dbe3-b71fcd83a711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 20.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 338kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 6.10MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 20.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 학습 및 테스트 데이터셋 로드\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f2aaada",
      "metadata": {
        "id": "2f2aaada"
      },
      "source": [
        "- FashionMNIST 데이터셋을 학습용과 테스트용으로 로드하는 과정을 실습합니다. 이는 신경망 학습 및 평가를 위한 필수적인 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a72d0eb",
      "metadata": {
        "id": "7a72d0eb"
      },
      "source": [
        "## 05-009 데이터 로더 생성\n",
        "- 이 실습에서는 학습 및 테스트 데이터셋을 배치 단위로 로드하기 위해 DataLoader를 생성하는 방법을 학습합니다. train_loader는 배치 크기가 64이고 데이터를 무작위로 섞으며, test_loader는 배치 크기가 64이고 데이터를 순차적으로 로드합니다. DataLoader는 대규모 데이터셋을 처리할 때 매우 유용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e774c28",
      "metadata": {
        "id": "7e774c28"
      },
      "outputs": [],
      "source": [
        "# 데이터 로더 생성\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57c469c3",
      "metadata": {
        "id": "57c469c3"
      },
      "source": [
        "- 학습 및 테스트 데이터셋을 처리할 DataLoader를 생성하는 과정을 실습합니다. 배치 처리를 통해 메모리 효율성을 높이고, 데이터셋을 효과적으로 로드할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c2d68e0",
      "metadata": {
        "id": "8c2d68e0"
      },
      "source": [
        "## 05-010 CNN 모델 클래스 정의\n",
        "- 이 실습에서는 CNN(Convolutional Neural Network) 모델을 정의합니다. 두 개의 컨볼루션 레이어, 각 레이어 뒤에 배치 정규화 및 드롭아웃을 적용하고, 최종적으로 두 개의 완전 연결 레이어를 사용하여 FashionMNIST 데이터셋의 분류 문제를 해결합니다. summary() 함수를 통해 모델 구조를 확인합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46464d58",
      "metadata": {
        "id": "46464d58"
      },
      "outputs": [],
      "source": [
        "# Sequential로 모델 정의\n",
        "model = nn.Sequential(\n",
        "    # 첫 번째 Conv + ReLU + MaxPool\n",
        "    nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    # 두 번째 Conv + ReLU + MaxPool\n",
        "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    # Flatten\n",
        "    nn.Flatten(),\n",
        "\n",
        "    # 첫 번째 Fully Connected + ReLU\n",
        "    nn.Linear(32 * 7 * 7, 128),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    # 두 번째 Fully Connected (출력층)\n",
        "    nn.Linear(128, 10)\n",
        ")\n",
        "model = model.to(device)\n",
        "summary(model, input_size=(64, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e30c7529",
      "metadata": {
        "id": "e30c7529"
      },
      "outputs": [],
      "source": [
        "# CNN 모델 정의\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # 첫 번째 컨볼루션 레이어\n",
        "        # 입력 채널: 1 (흑백 이미지), 출력 채널: 16, 커널 크기: 3x3, 패딩: 1\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
        "\n",
        "        # 두 번째 컨볼루션 레이어\n",
        "        # 입력 채널: 16, 출력 채널: 32, 커널 크기: 3x3, 패딩: 1\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "\n",
        "        # MaxPool 레이어 (다운샘플링)\n",
        "        # 커널 크기: 2x2, 스트라이드: 2\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # 첫 번째 완전 연결 (Fully Connected) 레이어\n",
        "        # 입력 크기: 32 * 7 * 7 (Conv2d 출력을 펼친 크기), 출력 크기: 128\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
        "\n",
        "        # 두 번째 완전 연결 레이어\n",
        "        # 입력 크기: 128, 출력 크기: 10 (클래스 개수)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "        # 활성화 함수\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 입력 데이터 크기: (batch_size, 1, 28, 28)\n",
        "\n",
        "        # 첫 번째 Conv + ReLU + MaxPool\n",
        "        # Conv 후 크기: (batch_size, 16, 28, 28)\n",
        "        # MaxPool 후 크기: (batch_size, 16, 14, 14)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "\n",
        "        # 두 번째 Conv + ReLU + MaxPool\n",
        "        # Conv 후 크기: (batch_size, 32, 14, 14)\n",
        "        # MaxPool 후 크기: (batch_size, 32, 7, 7)\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "\n",
        "        # Flatten: Conv 출력을 1차원 벡터로 펼침\n",
        "        # Flatten 후 크기: (batch_size, 32 * 7 * 7)\n",
        "        x = x.reshape(-1, 32 * 7 * 7)\n",
        "\n",
        "        # 첫 번째 Fully Connected + ReLU\n",
        "        # 출력 크기: (batch_size, 128)\n",
        "        x = self.relu(self.fc1(x))\n",
        "\n",
        "        # 두 번째 Fully Connected (출력층)\n",
        "        # 출력 크기: (batch_size, 10)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# 모델 요약 출력\n",
        "model = CNN().to(device)\n",
        "summary(model, input_size=(64, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7df41b1b",
      "metadata": {
        "id": "7df41b1b"
      },
      "source": [
        "- CNN 모델 클래스를 구현하고, 요약 정보를 통해 모델의 구조와 파라미터 수를 확인하는 과정을 실습합니다. CNN은 이미지 분류 문제에 효과적인 신경망 구조입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ba4f61b",
      "metadata": {
        "id": "3ba4f61b"
      },
      "source": [
        "## 05-011 손실 함수 및 옵티마이저 설정과 학습 수행\n",
        "- 이 실습에서는 모델 학습을 위한 손실 함수와 옵티마이저를 설정합니다. nn.CrossEntropyLoss()는 다중 클래스 분류 문제에 적합한 손실 함수로, 각 클래스의 확률을 기반으로 손실을 계산합니다. Adam 옵티마이저는 학습률(lr)을 0.0001로 설정하여 모델의 파라미터를 업데이트합니다. 이후, train() 함수와 evaluate() 함수를 호출하여 모델을 학습하고 평가합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()  # 모델을 학습 모드로 설정\n",
        "\n",
        "    running_loss = 0.0 # 미니 배치별 loss값을 누적할 변수\n",
        "\n",
        "    for datas, labels in train_loader: # 미니 배치 별 파라미터 업데이트 수행\n",
        "        datas, labels = datas.to(device), labels.to(device) # 미니 배치별 데이터와 레이블 장치 할당\n",
        "\n",
        "        # 순전파\n",
        "        outputs = model(datas)\n",
        "\n",
        "        # 손실 계산\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 기울기 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 역전파\n",
        "        loss.backward()\n",
        "\n",
        "        # 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 누적\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # 현재 Epoch의 평균 손실 값 계산 및 반환\n",
        "    return running_loss / len(train_loader)"
      ],
      "metadata": {
        "id": "GdCVL0R6DD8j"
      },
      "id": "GdCVL0R6DD8j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 함수 정의\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "\n",
        "    running_loss = 0.0 # 미니 배치별 loss값을 누적할 변수\n",
        "\n",
        "\n",
        "    with torch.no_grad():  # 평가 중에는 기울기 계산을 하지 않음\n",
        "        for datas, labels in test_loader: # 미니 배치 별 손실 계산\n",
        "            datas, labels = datas.to(device), labels.to(device) # 미니 배치별 데이터와 레이블 장치 할당\n",
        "\n",
        "            # 순전파\n",
        "            outputs = model(datas)\n",
        "\n",
        "            # 손실 계산\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 손실 누적\n",
        "            running_loss += loss.item()\n",
        "\n",
        "\n",
        "    # 현재 Epoch의 평균 손실 값 계산 및 반환\n",
        "    return running_loss / len(test_loader)"
      ],
      "metadata": {
        "id": "qYog_pu0Fkt8"
      },
      "id": "qYog_pu0Fkt8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa187b4a",
      "metadata": {
        "id": "aa187b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "87307f42-1b1a-4b0a-c195-a9edde1f8e94"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9c1fe793694e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 모델 학습(학습데이터)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()  # 다중 클래스 분류를 위한 손실 함수\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "# 학습 횟수 만큼 반복\n",
        "for epoch in range(10):\n",
        "\n",
        "    # 모델 학습(학습데이터)\n",
        "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # 모델 평가 (평가데이터)\n",
        "    test_loss = evaluate(model, test_loader, criterion, device)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print(f'Epoch {epoch+1} Train Loss : {train_loss} Test Loss : {test_loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a15d5305",
      "metadata": {
        "id": "a15d5305"
      },
      "source": [
        "- 손실 함수와 옵티마이저를 설정한 후, 모델을 학습하고 평가하는 과정을 실습합니다. 이 과정은 신경망 모델의 성능을 최적화하는 데 필수적입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2070b361",
      "metadata": {
        "id": "2070b361"
      },
      "source": [
        "## 연습문제-05-001 (배치, 3, 32, 32) 입력을 받는 CNN 모델 설계 (Sequential 방식)\n",
        "- 이 실습에서는 PyTorch Sequential 방식을 사용하여 (배치, 3, 32, 32) 형태의 이미지 입력을 받는 CNN 모델을 설계하는 방법을 학습합니다. 이 CNN 모델은 세 개의 합성곱 층을 사용하며, 각 층의 뒤에는 ReLU 활성화 함수와 Max Pooling을 적용합니다. 모델은 64개의 필터를 가진 마지막 합성곱 층에서 특징을 추출하고, 이를 완전히 연결된 층으로 전달합니다. 마지막 출력은 10개의 클래스에 대한 확률값을 나타내며, 소프트맥스 활성화 함수를 사용하여 이를 계산합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6022e7ef",
      "metadata": {
        "id": "6022e7ef"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "            # 첫 번째 합성곱층과 풀링층\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # 입력 채널 3, 출력 채널 16, 커널 크기 3x3, 패딩 1\n",
        "            nn.ReLU(),  # 활성화 함수\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 풀링층: 출력 크기를 절반으로 축소 (출력 크기: (16, 16))\n",
        "\n",
        "            # 두 번째 합성곱층과 풀링층\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # 입력 채널 16, 출력 채널 32\n",
        "            nn.ReLU(),  # 활성화 함수\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 출력 크기를 절반으로 축소 (출력 크기: (8, 8))\n",
        "\n",
        "            # 세 번째 합성곱층과 풀링층\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 입력 채널 32, 출력 채널 64\n",
        "            nn.ReLU(),  # 활성화 함수\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 출력 크기를 절반으로 축소 (출력 크기: (4, 4))\n",
        "\n",
        "            # Flatten 레이어\n",
        "            nn.Flatten(),  # (64, 4, 4) 형태의 출력을 이차원 텐서로 변환\n",
        "\n",
        "            # 첫 번째 완전 연결층\n",
        "            nn.Linear(64 * 4 * 4, 128),  # Conv 레이어 출력을 128차원 출력으로 변환\n",
        "            nn.ReLU(),  # 활성화 함수\n",
        "\n",
        "            # 최종 출력층\n",
        "            nn.Linear(128, 10)  # 10개의 클래스로 분류\n",
        "        )\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bd99f33",
      "metadata": {
        "id": "9bd99f33"
      },
      "source": [
        "- (배치, 3, 32, 32) 형태의 입력을 받는 CNN 모델을 Sequential 방식으로 설계하여 이미지 분류 문제를 해결하는 방법을 실습합니다. CNN의 기본 구조와 작동 원리에 대해 익히며, 합성곱, ReLU 활성화 함수, Max Pooling, 그리고 완전 연결 층의 역할을 이해합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa411d44",
      "metadata": {
        "id": "fa411d44"
      },
      "source": [
        "## 연습문제-05-002 (배치, 3, 224, 224) 입력을 받는 CNN 모델 설계 (Module 방식)\n",
        "- 이 실습에서는 PyTorch Module 방식을 사용하여 (배치, 3, 224, 224) 형태의 이미지 입력을 받는 CNN 모델을 설계하는 방법을 학습합니다. 이 모델은 더 큰 이미지(224x224 픽셀)를 처리할 수 있도록 설계되었으며, 네 개의 합성곱 층을 사용하여 이미지에서 점차적으로 더 추상적인 특징을 추출합니다. 각 합성곱 층 뒤에는 ReLU 활성화 함수와 Max Pooling을 적용하여 공간 정보를 줄이면서도 유용한 특징을 남깁니다. 마지막 완전 연결 층에서 추출된 특징을 기반으로 최종적으로 2개의 클래스를 분류합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4afd7815",
      "metadata": {
        "id": "4afd7815"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # 첫 번째 합성곱층과 풀링층\n",
        "        self.conv1 = nn.Conv2d(3, 256, kernel_size=3, padding=1)  # 입력 채널 3, 출력 채널 256, 커널 크기 3x3, 패딩 1\n",
        "        self.relu1 = nn.ReLU()  # 활성화 함수\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 풀링층: 출력 크기를 (112, 112)로 축소\n",
        "\n",
        "        # 두 번째 합성곱층과 풀링층\n",
        "        self.conv2 = nn.Conv2d(256, 128, kernel_size=3, padding=1)  # 입력 채널 256, 출력 채널 128\n",
        "        self.relu2 = nn.ReLU()  # 활성화 함수\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # 출력 크기를 (56, 56)으로 축소\n",
        "\n",
        "        # 세 번째 합성곱층과 풀링층\n",
        "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, padding=1)  # 입력 채널 128, 출력 채널 64\n",
        "        self.relu3 = nn.ReLU()  # 활성화 함수\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # 출력 크기를 (28, 28)으로 축소\n",
        "\n",
        "        # 네 번째 합성곱층과 풀링층\n",
        "        self.conv4 = nn.Conv2d(64, 32, kernel_size=3, padding=1)  # 입력 채널 64, 출력 채널 32\n",
        "        self.relu4 = nn.ReLU()  # 활성화 함수\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)  # 출력 크기를 (14, 14)로 축소\n",
        "\n",
        "        # Flatten 레이어\n",
        "        self.flatten = nn.Flatten()  # (32, 14, 14) 형태의 출력을 일차원 벡터로 변환\n",
        "\n",
        "        # 첫 번째 완전 연결층\n",
        "        self.fc1 = nn.Linear(32 * 14 * 14, 256)  # Conv 레이어 출력을 낮은 차원으로 줄임\n",
        "        self.relu_fc1 = nn.ReLU()  # 활성화 함수\n",
        "\n",
        "        # 두 번째 완전 연결층\n",
        "        self.fc2 = nn.Linear(256, 2)  # 두 개의 클래스로 최종 분류\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 첫 번째 합성곱층과 풀링층\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # 두 번째 합성곱층과 풀링층\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # 세 번째 합성곱층과 풀링층\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # 네 번째 합성곱층과 풀링층\n",
        "        x = self.conv4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        # Flatten 레이어\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        # 첫 번째 완전 연결층\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu_fc1(x)\n",
        "\n",
        "        # 두 번째 완전 연결층 (최종 출력)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = CNN()\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d582e07e",
      "metadata": {
        "id": "d582e07e"
      },
      "source": [
        "- (배치, 3, 224, 224) 형태의 입력을 받는 CNN 모델을 Sequential 방식으로 설계하여 고해상도 이미지 분류 문제를 해결하는 방법을 실습합니다. 더 깊은 네트워크 구조를 통해 고해상도 이미지를 처리하며, 각 층이 추출하는 특징과 네트워크의 학습 방식에 대해 이해합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd14a2f7",
      "metadata": {
        "id": "bd14a2f7"
      },
      "source": [
        "## 05-012 JAEN 패키지에서 CNN 모델 불러오기\n",
        "- 이 실습에서는 JAEN 패키지에서 제공하는 CNN 모델을 불러오고, 사전 학습된(pretrained) 가중치를 사용하여 모델을 초기화하는 방법을 학습합니다. summary() 함수를 사용하여 모델의 구조와 파라미터 수를 확인하여 모델이 올바르게 로드되었는지 검증합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f793a546",
      "metadata": {
        "id": "f793a546",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ba0dad-4d50-4e95-9ab7-adc7b8eacf9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained weights loaded successfully on cpu.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "CNNModel                                 [64, 10]                  --\n",
              "├─Sequential: 1-1                        [64, 32, 7, 7]            --\n",
              "│    └─Conv2d: 2-1                       [64, 16, 28, 28]          160\n",
              "│    └─ReLU: 2-2                         [64, 16, 28, 28]          --\n",
              "│    └─Conv2d: 2-3                       [64, 16, 28, 28]          2,320\n",
              "│    └─ReLU: 2-4                         [64, 16, 28, 28]          --\n",
              "│    └─MaxPool2d: 2-5                    [64, 16, 14, 14]          --\n",
              "│    └─Conv2d: 2-6                       [64, 32, 14, 14]          4,640\n",
              "│    └─ReLU: 2-7                         [64, 32, 14, 14]          --\n",
              "│    └─Conv2d: 2-8                       [64, 32, 14, 14]          9,248\n",
              "│    └─ReLU: 2-9                         [64, 32, 14, 14]          --\n",
              "│    └─MaxPool2d: 2-10                   [64, 32, 7, 7]            --\n",
              "├─Sequential: 1-2                        [64, 10]                  --\n",
              "│    └─Linear: 2-11                      [64, 128]                 200,832\n",
              "│    └─ReLU: 2-12                        [64, 128]                 --\n",
              "│    └─Linear: 2-13                      [64, 10]                  1,290\n",
              "==========================================================================================\n",
              "Total params: 218,490\n",
              "Trainable params: 218,490\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 311.58\n",
              "==========================================================================================\n",
              "Input size (MB): 0.20\n",
              "Forward/backward pass size (MB): 19.34\n",
              "Params size (MB): 0.87\n",
              "Estimated Total Size (MB): 20.41\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# JAEN 패키지에서 CNN 모델 가져오기\n",
        "from JAEN.models import CNNModel\n",
        "\n",
        "# CNN 모델 불러오기 (pretrained=True)\n",
        "model = CNNModel(pretrained=True)\n",
        "\n",
        "# 모델 정보 확인\n",
        "summary(model, (64, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1db2dfa9",
      "metadata": {
        "id": "1db2dfa9"
      },
      "source": [
        "- JAEN 패키지에서 CNN 모델을 불러오고, 모델 정보를 요약하여 확인하는 과정을 실습합니다. 이는 사전 학습된 모델을 사용할 때 유용합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91c74869",
      "metadata": {
        "id": "91c74869"
      },
      "source": [
        "## 05-013 기존 Conv Block 동결\n",
        "- 이 실습에서는 사전 학습된 CNN 모델의 일부 레이어(Conv Block)의 파라미터를 동결하여 학습 중에 업데이트되지 않도록 설정하는 방법을 학습합니다. 이는 transfer learning 기법의 일환으로, 특정 레이어의 가중치를 고정하여 새로운 데이터셋에 대해 학습할 때 유용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6f9c4db",
      "metadata": {
        "id": "f6f9c4db"
      },
      "outputs": [],
      "source": [
        "# 기존 Conv Block 동결\n",
        "for param in model.conv_layers.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "636fd64a",
      "metadata": {
        "id": "636fd64a"
      },
      "source": [
        "- CNN 모델의 기존 Conv Block을 동결하여 해당 레이어의 파라미터가 학습되지 않도록 설정하는 과정을 실습합니다. 이는 전이 학습 시 일반적인 기법입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bfe4149",
      "metadata": {
        "id": "5bfe4149"
      },
      "source": [
        "## 05-014 새로운 Fully Connected Block 설정\n",
        "- 이 실습에서는 CNN 모델의 Fully Connected Block을 새롭게 설정합니다. nn.Sequential()을 사용하여 새로운 은닉층과 드롭아웃 레이어를 추가하고, 출력층을 정의합니다. 모델을 디바이스(GPU 또는 CPU)로 이동한 후, summary() 함수를 사용하여 모델의 구조를 확인합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55151ae2",
      "metadata": {
        "id": "55151ae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e69c733-364c-45b6-bee5-68a5bcb607c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "CNNModel                                 [64, 10]                  --\n",
              "├─Sequential: 1-1                        [64, 32, 7, 7]            --\n",
              "│    └─Conv2d: 2-1                       [64, 16, 28, 28]          (160)\n",
              "│    └─ReLU: 2-2                         [64, 16, 28, 28]          --\n",
              "│    └─Conv2d: 2-3                       [64, 16, 28, 28]          (2,320)\n",
              "│    └─ReLU: 2-4                         [64, 16, 28, 28]          --\n",
              "│    └─MaxPool2d: 2-5                    [64, 16, 14, 14]          --\n",
              "│    └─Conv2d: 2-6                       [64, 32, 14, 14]          (4,640)\n",
              "│    └─ReLU: 2-7                         [64, 32, 14, 14]          --\n",
              "│    └─Conv2d: 2-8                       [64, 32, 14, 14]          (9,248)\n",
              "│    └─ReLU: 2-9                         [64, 32, 14, 14]          --\n",
              "│    └─MaxPool2d: 2-10                   [64, 32, 7, 7]            --\n",
              "├─Sequential: 1-2                        [64, 10]                  --\n",
              "│    └─Linear: 2-11                      [64, 64]                  100,416\n",
              "│    └─ReLU: 2-12                        [64, 64]                  --\n",
              "│    └─Dropout: 2-13                     [64, 64]                  --\n",
              "│    └─Linear: 2-14                      [64, 10]                  650\n",
              "==========================================================================================\n",
              "Total params: 117,434\n",
              "Trainable params: 101,066\n",
              "Non-trainable params: 16,368\n",
              "Total mult-adds (M): 305.12\n",
              "==========================================================================================\n",
              "Input size (MB): 0.20\n",
              "Forward/backward pass size (MB): 19.31\n",
              "Params size (MB): 0.47\n",
              "Estimated Total Size (MB): 19.98\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# 새로운 Fully Connected Block 설정\n",
        "model.fc_layers = nn.Sequential(\n",
        "    nn.Linear(32 * 7 * 7, 64),  # 첫 번째 은닉층\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),           # 드롭아웃 추가\n",
        "    nn.Linear(64, 10)           # 출력층 (활성화 함수 없음)\n",
        ")\n",
        "\n",
        "# 디바이스 설정 (GPU 또는 CPU)\n",
        "model = model.to(device)\n",
        "summary(model, input_size=(64, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f933593",
      "metadata": {
        "id": "3f933593"
      },
      "source": [
        "- 새로운 Fully Connected Block을 설정하고, 모델의 구조와 파라미터 수를 요약하여 확인하는 과정을 실습합니다. 이는 모델 구조를 조정하고 최적화하는 데 중요한 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c27a949c",
      "metadata": {
        "id": "c27a949c"
      },
      "source": [
        "## 05-015 손실 함수 및 최적화 도구 정의와 학습 수행\n",
        "- 이 실습에서는 모델 학습을 위한 손실 함수와 옵티마이저를 설정합니다. nn.CrossEntropyLoss()는 다중 클래스 분류 문제에 적합한 손실 함수로, 각 클래스의 확률을 기반으로 손실을 계산합니다. Adam 옵티마이저는 학습률(lr)을 0.0001로 설정하여 모델의 파라미터를 업데이트합니다. 이후, train() 함수와 evaluate() 함수를 호출하여 모델을 학습하고 평가합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d2b63ee",
      "metadata": {
        "id": "6d2b63ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f897e5-0148-4930-f665-0dfdc9f2653c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Train Loss : 0.9190170404308641 Test Loss : 0.5360199334515128\n",
            "Epoch 2 Train Loss : 0.562107907143483 Test Loss : 0.45694804590219146\n",
            "Epoch 3 Train Loss : 0.48845862600404316 Test Loss : 0.42060009594176223\n",
            "Epoch 4 Train Loss : 0.4508541450539886 Test Loss : 0.3985055926119446\n",
            "Epoch 5 Train Loss : 0.42382766860825166 Test Loss : 0.3827094721376516\n",
            "Epoch 6 Train Loss : 0.4050813811197718 Test Loss : 0.3705502521650047\n",
            "Epoch 7 Train Loss : 0.3883679088975575 Test Loss : 0.36144249103251536\n",
            "Epoch 8 Train Loss : 0.3774939282838978 Test Loss : 0.3541893147549052\n",
            "Epoch 9 Train Loss : 0.36592817486031476 Test Loss : 0.346701573888967\n",
            "Epoch 10 Train Loss : 0.3560539771721307 Test Loss : 0.3427906078138169\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()  # 다중 클래스 분류를 위한 손실 함수\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "# 학습 횟수 만큼 반복\n",
        "for epoch in range(10):\n",
        "\n",
        "    # 모델 학습(학습데이터)\n",
        "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # 모델 평가 (평가데이터)\n",
        "    test_loss = evaluate(model, test_loader, criterion, device)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print(f'Epoch {epoch+1} Train Loss : {train_loss} Test Loss : {test_loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4e24bad",
      "metadata": {
        "id": "d4e24bad"
      },
      "source": [
        "- 손실 함수와 최적화 도구를 설정한 후, 모델을 학습하고 평가하는 과정을 실습합니다. 이 과정은 신경망 모델의 성능을 최적화하는 데 필수적입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11c332d3",
      "metadata": {
        "id": "11c332d3"
      },
      "source": [
        "## 05-016 마지막 두 Conv 레이어만 학습하도록 설정\n",
        "- 이 실습에서는 CNN 모델에서 마지막 두 컨볼루션 레이어의 파라미터만 학습하도록 설정합니다. named_parameters() 메서드를 사용하여 각 레이어의 이름과 파라미터를 반복하고, 특정 레이어에 대해서만 requires_grad를 True로 설정합니다. 이를 통해 모델의 특정 부분만 학습하여 과적합을 방지하고 성능을 최적화할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a67cf890",
      "metadata": {
        "id": "a67cf890"
      },
      "outputs": [],
      "source": [
        "# 마지막 두 Conv 레이어만 학습하도록 설정\n",
        "for name, p in model.conv_layers.named_parameters():\n",
        "    if name in ['5.weight', '5.bias', '7.weight', '7.bias']:\n",
        "        p.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "985b9cde",
      "metadata": {
        "id": "985b9cde"
      },
      "source": [
        "- CNN 모델의 마지막 두 Conv 레이어만 학습하도록 설정하는 과정을 실습합니다. 이는 전이 학습 시 효과적인 접근 방식입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e075d17",
      "metadata": {
        "id": "8e075d17"
      },
      "source": [
        "## 05-017 손실 함수 및 최적화 도구 정의와 학습 수행\n",
        "- 이 실습에서는 모델 학습을 위한 손실 함수와 옵티마이저를 설정합니다. nn.CrossEntropyLoss()는 다중 클래스 분류 문제에 적합한 손실 함수로, 각 클래스의 확률을 기반으로 손실을 계산합니다. Adam 옵티마이저는 학습률(lr)을 0.0001로 설정하여 모델의 파라미터를 업데이트합니다. 이후, train() 함수와 evaluate() 함수를 호출하여 모델을 학습하고 평가합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff67b6c9",
      "metadata": {
        "id": "ff67b6c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e317166-efd4-4b43-ce9a-334ca6d936ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Train Loss : 0.33735390778766006 Test Loss : 0.3262163572440481\n",
            "Epoch 2 Train Loss : 0.3232256932092755 Test Loss : 0.3161832512279225\n",
            "Epoch 3 Train Loss : 0.3094898876207851 Test Loss : 0.31217089029634076\n",
            "Epoch 4 Train Loss : 0.29896421433448284 Test Loss : 0.3059644358363121\n",
            "Epoch 5 Train Loss : 0.29326724744777183 Test Loss : 0.30353133589219133\n",
            "Epoch 6 Train Loss : 0.2840276809055795 Test Loss : 0.30029808566164057\n",
            "Epoch 7 Train Loss : 0.27843418814289544 Test Loss : 0.29711983018335264\n",
            "Epoch 8 Train Loss : 0.2730487060945616 Test Loss : 0.29351744096085525\n",
            "Epoch 9 Train Loss : 0.2681659748956466 Test Loss : 0.29095555020935215\n",
            "Epoch 10 Train Loss : 0.2610217322116849 Test Loss : 0.2896314877660791\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()  # 다중 클래스 분류를 위한 손실 함수\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "# 학습 횟수 만큼 반복\n",
        "for epoch in range(10):\n",
        "\n",
        "    # 모델 학습(학습데이터)\n",
        "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # 모델 평가 (평가데이터)\n",
        "    test_loss = evaluate(model, test_loader, criterion, device)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print(f'Epoch {epoch+1} Train Loss : {train_loss} Test Loss : {test_loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42abce61",
      "metadata": {
        "id": "42abce61"
      },
      "source": [
        "- 손실 함수와 최적화 도구를 설정한 후, 모델을 학습하고 평가하는 과정을 실습합니다. 이 과정은 신경망 모델의 성능을 최적화하는 데 필수적입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "tM6U2OTiN3Tn",
        "outputId": "cd0d29e0-17fd-4c8a-ca58-6d11912e5b0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tM6U2OTiN3Tn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU()\n",
              "    (7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU()\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc_layers): Sequential(\n",
              "    (0): Linear(in_features=1568, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85a832c2",
      "metadata": {
        "id": "85a832c2"
      },
      "source": [
        "# 06. 순환신경망 (RNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92ce5eab",
      "metadata": {
        "id": "92ce5eab"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install JAEN transformers -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ba38727",
      "metadata": {
        "id": "5ba38727"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from JAEN.utils import plot_training_results\n",
        "\n",
        "# device 설정 (GPU가 사용 가능하면 GPU로, 그렇지 않으면 CPU 사용)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e78464",
      "metadata": {
        "id": "32e78464"
      },
      "source": [
        "## 06-001 Tokenizer 불러오기\n",
        "- 이 실습에서는 Hugging Face의 Transformers 라이브러리를 사용하여 BERT 모델의 토크나이저를 불러오는 방법을 학습합니다. AutoTokenizer를 사용하여 'bert-base-cased' 모델에 맞는 토크나이저를 자동으로 가져오며, 이 토크나이저는 입력 텍스트를 BERT 모델에서 처리할 수 있는 형식으로 변환하는 데 사용됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe4e353e",
      "metadata": {
        "id": "fe4e353e"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02c2e1a0",
      "metadata": {
        "id": "02c2e1a0"
      },
      "source": [
        "- BERT 모델에 사용할 토크나이저를 불러오는 과정을 실습합니다. 이는 NLP 작업에서 텍스트를 준비하는 데 중요한 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "348570d2",
      "metadata": {
        "id": "348570d2"
      },
      "source": [
        "## 06-002 토큰화 실습\n",
        "- 이 실습에서는 불러온 BERT 토크나이저를 사용하여 주어진 텍스트 'AI Essential'을 토크나이징하는 방법을 학습합니다. 토크나이저는 입력 문자열을 BERT 모델이 이해할 수 있는 형식으로 변환하며, 각 단어를 고유한 ID로 매핑합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b414ae42",
      "metadata": {
        "id": "b414ae42"
      },
      "outputs": [],
      "source": [
        "tokenizer(\"AI Essential\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8301135b",
      "metadata": {
        "id": "8301135b"
      },
      "source": [
        "- BERT 토크나이저를 사용하여 텍스트를 토크나이즈하는 과정을 실습합니다. 이는 NLP 모델에서 입력 데이터를 준비하는 데 필수적인 과정입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d225d730",
      "metadata": {
        "id": "d225d730"
      },
      "source": [
        "## 06-003 토큰화된 텍스트 확인\n",
        "- 이 실습에서는 BERT 토크나이저를 사용하여 텍스트 'AI Essential'을 토큰화한 결과를 확인합니다. tokenizer.tokenize() 메서드를 통해 입력 텍스트를 개별 토큰으로 분리하며, 각 토큰은 BERT 모델이 처리할 수 있는 형태로 변환됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a57308",
      "metadata": {
        "id": "27a57308"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.tokenize(\"AI Essential\")\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4096a02",
      "metadata": {
        "id": "a4096a02"
      },
      "source": [
        "- 주어진 텍스트를 BERT 토크나이저를 사용하여 토큰화하고, 생성된 토큰을 확인하는 과정을 실습합니다. 이는 NLP 모델에서 데이터를 준비하는 중요한 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a8fb5a4",
      "metadata": {
        "id": "8a8fb5a4"
      },
      "source": [
        "## 06-004 토큰을 ID로 변환\n",
        "- 이 실습에서는 BERT 토크나이저를 사용하여 토큰화된 텍스트를 고유한 정수 ID로 변환하는 방법을 학습합니다. tokenizer.convert_tokens_to_ids() 메서드를 통해 각 토큰을 모델에서 사용하는 입력 형태로 변환합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "842fbde8",
      "metadata": {
        "id": "842fbde8"
      },
      "outputs": [],
      "source": [
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "ids"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f33d6f3a",
      "metadata": {
        "id": "f33d6f3a"
      },
      "source": [
        "- 토큰화된 텍스트를 BERT 모델의 입력으로 사용할 수 있도록 정수 ID로 변환하는 과정을 실습합니다. 이는 NLP 모델에 데이터를 입력하는 데 필수적인 과정입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4569af8a",
      "metadata": {
        "id": "4569af8a"
      },
      "source": [
        "## 06-005 토큰 ID를 텍스트로 디코딩\n",
        "- 이 실습에서는 BERT 토크나이저를 사용하여 토큰 ID를 다시 원래의 텍스트로 디코딩하는 방법을 학습합니다. tokenizer.decode() 메서드를 사용하여 ID를 입력하면, 모델이 이해할 수 있는 형태의 원본 문자열로 복원됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d85beae",
      "metadata": {
        "id": "5d85beae"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61504063",
      "metadata": {
        "id": "61504063"
      },
      "source": [
        "- 토큰 ID를 사용하여 원래의 텍스트로 디코딩하는 과정을 실습합니다. 이는 NLP 작업에서 데이터를 확인하고 검증하는 데 유용합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c863e8",
      "metadata": {
        "id": "01c863e8"
      },
      "source": [
        "## 06-006 임베딩 모듈 생성 및 사용\n",
        "- 이 실습에서는 PyTorch의 nn.Embedding 모듈을 사용하여 정수 인덱스를 고차원 벡터로 변환하는 방법을 학습합니다. 임베딩 레이어를 생성하고, 입력 데이터로 주어진 정수 인덱스를 벡터로 변환합니다. 이 과정은 자연어 처리(NLP) 작업에서 단어 또는 토큰을 임베딩하는 데 사용됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91ba0a6a",
      "metadata": {
        "id": "91ba0a6a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 임베딩 모듈 생성 (정수 인덱스 10개, 각 인덱스는 5차원의 벡터로 매핑)\n",
        "embedding_layer = nn.Embedding(num_embeddings=10, embedding_dim=5)\n",
        "\n",
        "# 임베딩에 사용할 예시 입력 데이터 (정수 인덱스)\n",
        "# 여기서 [2, 5, 7]은 단어나 토큰에 해당한다고 가정\n",
        "input_data = torch.tensor([2, 5, 7])\n",
        "\n",
        "# 임베딩 레이어에 입력 데이터를 전달하여 벡터 변환\n",
        "embedded_output = embedding_layer(input_data)\n",
        "\n",
        "print(\"입력 데이터 (정수 인덱스):\", input_data)\n",
        "print(\"임베딩 결과 (벡터):\\n\", embedded_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeaf5f9e",
      "metadata": {
        "id": "eeaf5f9e"
      },
      "source": [
        "- 임베딩 모듈을 생성하고, 정수 인덱스를 벡터로 변환하는 과정을 실습합니다. 이는 NLP 모델에서 단어 표현을 얻는 데 필수적인 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d7205ae",
      "metadata": {
        "id": "9d7205ae"
      },
      "source": [
        "## 06-007 코퍼스 및 레이블 정의\n",
        "- 이 실습에서는 간단한 문장 리스트(corpus)와 각 문장에 대한 레이블(y)을 정의합니다. y는 부정(0)과 긍정(1)으로 이루어져 있으며, 각 문장의 감정 평가를 나타냅니다. 이러한 데이터는 감정 분석 모델을 학습시키는 데 사용됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88feff79",
      "metadata": {
        "id": "88feff79"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "corpus = [\n",
        "    'very good nice quality',\n",
        "    'stop lying',\n",
        "    'ugly terrible',\n",
        "    'excellent work',\n",
        "    'adorable lovely',\n",
        "    'bad',\n",
        "    'great nice'\n",
        "]\n",
        "y = torch.FloatTensor([1, 0, 0, 1, 1, 0, 1]).reshape(-1, 1)  # 0: 부정, 1: 긍정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b453ce74",
      "metadata": {
        "id": "b453ce74"
      },
      "source": [
        "- 감정 분석을 위한 문장 목록과 레이블을 정의하는 과정을 실습합니다. 이는 NLP 모델 학습을 위한 데이터 준비의 기초 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55ac7668",
      "metadata": {
        "id": "55ac7668"
      },
      "source": [
        "## 06-008 GPT2 토크나이저로 문장 변환\n",
        "- 이 실습에서는 GPT2 모델의 토크나이저를 사용하여 문장 목록(corpus)을 토큰화합니다. AutoTokenizer를 통해 사전 학습된 토크나이저를 불러오고, clean_up_tokenization_spaces=True 옵션을 통해 불필요한 공백을 제거합니다. 변환된 시퀀스는 각 문장을 토큰 ID의 리스트로 표현합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81bb5ada",
      "metadata": {
        "id": "81bb5ada",
        "outputId": "0fe96fd8-0688-414a-8493-5997973b4560"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[14, 6, 2, 10], [11, 9], [13, 12], [5, 15], [3, 8], [4], [7, 2]]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# GPT2 토크나이저 불러오기\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    'gmteacher/simple-word-tokenizer',\n",
        "    clean_up_tokenization_spaces=True)\n",
        "seqs = tokenizer(corpus)['input_ids']\n",
        "seqs  # 변환된 시퀀스"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da4549a1",
      "metadata": {
        "id": "da4549a1"
      },
      "source": [
        "- GPT2 토크나이저를 사용하여 문장 목록을 토큰화하고, 변환된 시퀀스를 확인하는 과정을 실습합니다. 이는 NLP 모델의 입력 데이터를 준비하는 데 필수적인 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34d9310b",
      "metadata": {
        "id": "34d9310b"
      },
      "source": [
        "## 06-009 토큰 ID를 단어로 복원\n",
        "- 이 실습에서는 GPT2 토크나이저를 사용하여 토큰 ID를 원래의 단어로 복원합니다. tokenizer.decode() 메서드를 사용하여 각 시퀀스를 입력하면, 모델이 이해할 수 있는 형태의 원본 문자열로 변환됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f529949",
      "metadata": {
        "id": "7f529949",
        "outputId": "73d1b0eb-ac3b-41aa-a6b1-608c7f2f6dda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['very good nice quality',\n",
              " 'stop lying',\n",
              " 'ugly terrible',\n",
              " 'excellent work',\n",
              " 'adorable lovely',\n",
              " 'bad',\n",
              " 'great nice']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 시퀀스를 단어로 복원\n",
        "[tokenizer.decode(seq) for seq in seqs]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04914596",
      "metadata": {
        "id": "04914596"
      },
      "source": [
        "- 토큰 ID를 사용하여 원래의 단어로 복원하는 과정을 실습합니다. 이는 NLP 작업에서 데이터를 확인하고 검증하는 데 유용합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55cdd7a6",
      "metadata": {
        "id": "55cdd7a6"
      },
      "source": [
        "## 06-010 시퀀스를 텐서로 변환하고 패딩\n",
        "- 이 실습에서는 토큰 ID로 변환된 시퀀스들을 PyTorch 텐서로 변환한 후, pad_sequence() 함수를 사용하여 패딩을 적용합니다. 패딩을 통해 각 시퀀스의 길이를 동일하게 맞추어 배치 처리를 용이하게 합니다. batch_first=True로 설정하여 배치가 첫 번째 차원에 오도록 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0befee2",
      "metadata": {
        "id": "f0befee2",
        "outputId": "86d12b59-473a-499e-d4f5-3d763280a9d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[14,  6,  2, 10],\n",
              "        [11,  9,  0,  0],\n",
              "        [13, 12,  0,  0],\n",
              "        [ 5, 15,  0,  0],\n",
              "        [ 3,  8,  0,  0],\n",
              "        [ 4,  0,  0,  0],\n",
              "        [ 7,  2,  0,  0]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# 각 시퀀스를 텐서로 변환\n",
        "seqs = [torch.tensor(seq) for seq in seqs]\n",
        "\n",
        "# 패딩\n",
        "x = pad_sequence(seqs, batch_first=True)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52c3a965",
      "metadata": {
        "id": "52c3a965"
      },
      "source": [
        "- 각 시퀀스를 텐서로 변환하고, 패딩을 적용하여 배치 처리를 위한 텐서를 준비하는 과정을 실습합니다. 이는 시퀀스 데이터 처리에서 매우 중요한 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83aee986",
      "metadata": {
        "id": "83aee986"
      },
      "source": [
        "## 06-011 텍스트 분류기 모델 정의\n",
        "- 이 실습에서는 텍스트 분류를 위한 신경망 모델을 정의합니다. TextClassifier 클래스는 입력 데이터를 임베딩 레이어를 통해 고차원 벡터로 변환하고, 평탄화(flatten)한 후 완전 연결 레이어를 사용하여 클래스를 예측합니다. 마지막으로, Sigmoid 활성화 함수를 사용하여 출력을 변환합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ce8bc9b",
      "metadata": {
        "id": "3ce8bc9b"
      },
      "outputs": [],
      "source": [
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, seq_len, num_class):\n",
        "        super().__init__()\n",
        "        # 임베딩 계층 추가\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.flat = nn.Flatten()\n",
        "        self.fc = nn.Linear(embed_dim*seq_len, num_class)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.flat(out)\n",
        "        out = self.fc(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d974331",
      "metadata": {
        "id": "1d974331"
      },
      "source": [
        "- 텍스트 분류를 위한 신경망 모델을 정의하는 과정을 실습합니다. 이 모델은 NLP 작업에서 입력 데이터를 분류하는 데 사용됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aba880ed",
      "metadata": {
        "id": "aba880ed"
      },
      "source": [
        "## 06-012 텍스트 분류기 모델 인스턴스 생성 및 출력 테스트\n",
        "- 이 실습에서는 TextClassifier 모델의 인스턴스를 생성하고, 입력 데이터에 대한 출력 결과의 형태를 확인합니다. torch.manual_seed(0)으로 랜덤 시드를 설정하여 결과의 재현성을 보장합니다. 모델의 출력이 올바르게 형성되는지를 테스트합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ff41f4",
      "metadata": {
        "id": "56ff41f4"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "# 모델 인스턴스 생성\n",
        "model = TextClassifier(tokenizer.vocab_size, 2, x.shape[1], 1).to(device)\n",
        "\n",
        "# 출력 테스트\n",
        "output = model(x[:1].to(device))\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86960cb",
      "metadata": {
        "id": "e86960cb"
      },
      "source": [
        "- 텍스트 분류기 모델을 인스턴스화하고, 입력 데이터를 사용하여 출력의 형태를 확인하는 과정을 실습합니다. 이는 모델이 기대한 대로 작동하는지 검증하는 데 중요합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9f7381b",
      "metadata": {
        "id": "b9f7381b"
      },
      "source": [
        "## 06-013 장치 적용\n",
        "- 이 실습에서는 입력 데이터 x와 타겟 데이터 y를 설정한 장치(GPU 또는 CPU)로 이동합니다. PyTorch에서는 모델과 데이터가 동일한 장치에 있어야 연산이 가능하므로, 이를 통해 학습 및 추론을 위한 준비를 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbc0caba",
      "metadata": {
        "id": "dbc0caba"
      },
      "outputs": [],
      "source": [
        "# 장치 적용\n",
        "x = x.to(device)\n",
        "y = y.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54c8f1df",
      "metadata": {
        "id": "54c8f1df"
      },
      "source": [
        "- 입력 데이터와 타겟 데이터를 장치에 적용하는 과정을 실습합니다. 이는 PyTorch에서 효율적인 계산을 위한 필수적인 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbfebf80",
      "metadata": {
        "id": "bbfebf80"
      },
      "source": [
        "## 06-014 모델 학습 및 손실 계산\n",
        "- 이 실습에서는 정의한 텍스트 분류기 모델을 학습시키고 손실을 계산하는 과정을 구현합니다. BCELoss를 손실 함수로 사용하고, Adam 옵티마이저를 통해 모델의 파라미터를 업데이트합니다. 지정된 최대 에폭 수만큼 모델을 학습시키며, 주기적으로 손실 값을 출력합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "175c2128",
      "metadata": {
        "id": "175c2128"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.BCELoss()  # 손실 함수\n",
        "optimizer = optim.Adam(model.parameters())  # 최적화 도구(optimizer)\n",
        "\n",
        "epochs = 30000  # 최대 에폭 지정\n",
        "results = {'cost':[]}\n",
        "\n",
        "model.train()  # 학습 모드 설정\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    h = model(x)  # 예측 값 생성(추론)\n",
        "    loss = loss_fn(h, y)  # 손실 계산\n",
        "\n",
        "    optimizer.zero_grad()  # 미분 값 초기화\n",
        "    loss.backward()  # 역전파(미분 계산)\n",
        "    optimizer.step()  # 업데이트 진행\n",
        "\n",
        "    results['cost'].append(loss.item())\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f'epoch: {epoch:4d}, cost: {results[\"cost\"][-1]:.10f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3b7c195",
      "metadata": {
        "id": "b3b7c195"
      },
      "source": [
        "- 모델을 학습시키고 손실을 계산하여 업데이트하는 과정을 실습합니다. 학습 과정의 손실 변화를 모니터링하는 것은 모델의 성능을 이해하는 데 중요합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0442cd5e",
      "metadata": {
        "id": "0442cd5e"
      },
      "source": [
        "## 06-015 예측 값을 클래스로 변환\n",
        "- 이 실습에서는 모델의 예측 값을 시그모이드 결과를 기반으로 클래스로 변환하는 방법을 학습합니다. h.reshape(-1)로 예측 결과를 평탄화한 후, 0.5를 기준으로 이진 클래스로 변환합니다. 실제 값과 예측 값을 출력하여 모델의 성능을 평가합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec0f207",
      "metadata": {
        "id": "8ec0f207"
      },
      "outputs": [],
      "source": [
        "# 예측 값 생성\n",
        "h = model(x)\n",
        "\n",
        "# 예측 값(시그모이드 값)을 클래스로 변환\n",
        "pred = (h.reshape(-1).detach().cpu() > 0.5).to(torch.float32)\n",
        "\n",
        "print(f'실제 값: {y.reshape(-1)}')\n",
        "print(f'예측 값: {pred}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646fc83e",
      "metadata": {
        "id": "646fc83e"
      },
      "source": [
        "- 모델의 예측 값을 클래스 형태로 변환하고, 실제 값과 비교하여 출력하는 과정을 실습합니다. 이는 모델의 예측 정확도를 확인하는 데 중요합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce186c6c",
      "metadata": {
        "id": "ce186c6c"
      },
      "source": [
        "## 06-016 코퍼스 및 레이블 정의\n",
        "- 이 실습에서는 간단한 문장 리스트(corpus)와 각 문장에 대한 레이블(y)을 정의합니다. y는 부정(0)과 긍정(1)으로 이루어져 있으며, 각 문장의 감정 평가를 나타냅니다. 이러한 데이터는 감정 분석 모델을 학습시키는 데 사용됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "012437c5",
      "metadata": {
        "id": "012437c5"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    'very good nice quality',\n",
        "    'stop lying',\n",
        "    'ugly terrible',\n",
        "    'excellent work',\n",
        "    'adorable lovely',\n",
        "    'bad',\n",
        "    'great nice'\n",
        "]\n",
        "y = torch.FloatTensor([1, 0, 0, 1, 1, 0, 1]).reshape(-1, 1)  # 0: 부정, 1: 긍정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa4976c7",
      "metadata": {
        "id": "fa4976c7"
      },
      "source": [
        "- 감정 분석을 위한 문장 목록과 레이블을 정의하는 과정을 실습합니다. 이는 NLP 모델 학습을 위한 데이터 준비의 기초 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a3911a8",
      "metadata": {
        "id": "4a3911a8"
      },
      "source": [
        "## 06-017 GPT2 토크나이저로 문장 변환\n",
        "- 이 실습에서는 GPT2 모델의 토크나이저를 사용하여 문장 목록(corpus)을 토큰화합니다. AutoTokenizer를 통해 사전 학습된 토크나이저를 불러오고, clean_up_tokenization_spaces=True 옵션을 통해 불필요한 공백을 제거합니다. 변환된 시퀀스는 각 문장을 토큰 ID의 리스트로 표현합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5df0d85",
      "metadata": {
        "id": "c5df0d85"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# GPT2 토크나이저 불러오기\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    'gmteacher/simple-word-tokenizer',\n",
        "    clean_up_tokenization_spaces=True)\n",
        "seqs = tokenizer(corpus)['input_ids']\n",
        "seqs  # 변환된 시퀀스"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90fa1119",
      "metadata": {
        "id": "90fa1119"
      },
      "source": [
        "- GPT2 토크나이저를 사용하여 문장 목록을 토큰화하고, 변환된 시퀀스를 확인하는 과정을 실습합니다. 이는 NLP 모델의 입력 데이터를 준비하는 데 필수적인 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7407829f",
      "metadata": {
        "id": "7407829f"
      },
      "source": [
        "## 06-018 토큰 ID를 단어로 복원\n",
        "- 이 실습에서는 GPT2 토크나이저를 사용하여 토큰 ID를 원래의 단어로 복원합니다. tokenizer.decode() 메서드를 사용하여 각 시퀀스를 입력하면, 모델이 이해할 수 있는 형태의 원본 문자열로 변환됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ea75d0",
      "metadata": {
        "id": "49ea75d0"
      },
      "outputs": [],
      "source": [
        "# 시퀀스를 단어로 복원\n",
        "[tokenizer.decode(seq) for seq in seqs]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b713038f",
      "metadata": {
        "id": "b713038f"
      },
      "source": [
        "- 토큰 ID를 사용하여 원래의 단어로 복원하는 과정을 실습합니다. 이는 NLP 작업에서 데이터를 확인하고 검증하는 데 유용합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada372d3",
      "metadata": {
        "id": "ada372d3"
      },
      "source": [
        "## 06-019 시퀀스를 텐서로 변환하고 패딩\n",
        "- 이 실습에서는 토큰 ID로 변환된 시퀀스들을 PyTorch 텐서로 변환한 후, pad_sequence() 함수를 사용하여 패딩을 적용합니다. 패딩을 통해 각 시퀀스의 길이를 동일하게 맞추어 배치 처리를 용이하게 합니다. batch_first=True로 설정하여 배치가 첫 번째 차원에 오도록 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5da108e",
      "metadata": {
        "id": "f5da108e"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# 각 시퀀스를 텐서로 변환\n",
        "seqs = [torch.tensor(seq) for seq in seqs]\n",
        "\n",
        "# 패딩\n",
        "x = pad_sequence(seqs, batch_first=True)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42f3c331",
      "metadata": {
        "id": "42f3c331"
      },
      "source": [
        "- 각 시퀀스를 텐서로 변환하고, 패딩을 적용하여 배치 처리를 위한 텐서를 준비하는 과정을 실습합니다. 이는 시퀀스 데이터 처리에서 매우 중요한 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0307048",
      "metadata": {
        "id": "d0307048"
      },
      "source": [
        "## 06-020 텍스트 분류기 모델 정의\n",
        "- 이 실습에서는 텍스트 분류를 위한 신경망 모델을 정의합니다. TextClassifier 클래스는 입력 데이터를 임베딩 레이어를 통해 고차원 벡터로 변환한 후, LSTM(Long Short-Term Memory) 계층을 사용하여 순차적 특성을 학습합니다. LSTM의 마지막 출력(hidden state)을 이용해 완전 연결 레이어로 클래스를 예측하고, Sigmoid 활성화 함수를 통해 최종 출력을 얻습니다. 이 모델은 자연어 처리 작업에서 시퀀스 데이터를 기반으로 한 분류 작업에 사용됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d929d3db",
      "metadata": {
        "id": "d929d3db"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, num_class):\n",
        "        super().__init__()\n",
        "        # 임베딩 계층 추가\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_class)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out, _ = self.lstm(out)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        out = self.sigmoid(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e26a0b96",
      "metadata": {
        "id": "e26a0b96"
      },
      "source": [
        "- 이 실습에서는 LSTM 계층을 포함한 텍스트 분류 모델을 정의하는 과정을 다룹니다. 모델은 임베딩 계층과 LSTM 계층을 활용하여 입력 텍스트의 순차적 특성을 반영한 분류 작업을 수행합니다. LSTM의 최종 출력을 사용하여 여러 클래스로의 분류를 예측합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e891e1",
      "metadata": {
        "id": "70e891e1"
      },
      "source": [
        "## 06-021 텍스트 분류기 모델 인스턴스 생성 및 출력 테스트\n",
        "- 이 실습에서는 TextClassifier 모델의 인스턴스를 생성하고, 입력 데이터에 대한 출력 결과의 형태를 확인합니다. 모델 생성 시, 임베딩 차원과 LSTM의 은닉 상태 크기(hidden_size)를 설정합니다. torch.manual_seed(0)을 사용해 랜덤 시드를 고정하여 재현성을 보장합니다. 모델이 입력 데이터를 기반으로 출력이 올바르게 형성되는지를 테스트합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b6b4e5",
      "metadata": {
        "id": "97b6b4e5"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "hidden_size = 128\n",
        "# 모델 인스턴스 생성\n",
        "model = TextClassifier(tokenizer.vocab_size, 2, hidden_size, 1).to(device)\n",
        "\n",
        "# 출력 테스트\n",
        "output = model(x[:1].to(device))\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a4ed444",
      "metadata": {
        "id": "9a4ed444"
      },
      "source": [
        "- 텍스트 분류기 모델을 인스턴스화하고, 입력 데이터를 사용하여 출력의 형태를 확인하는 과정을 실습합니다. 이는 모델이 기대한 대로 작동하는지 검증하는 데 중요한 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e359e6b9",
      "metadata": {
        "id": "e359e6b9"
      },
      "source": [
        "## 06-022 장치 적용\n",
        "- 이 실습에서는 입력 데이터 x와 타겟 데이터 y를 설정한 장치(GPU 또는 CPU)로 이동합니다. PyTorch에서는 모델과 데이터가 동일한 장치에 있어야 연산이 가능하므로, 이를 통해 학습 및 추론을 위한 준비를 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49b4a9d4",
      "metadata": {
        "id": "49b4a9d4"
      },
      "outputs": [],
      "source": [
        "# 장치 적용\n",
        "x = x.to(device)\n",
        "y = y.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89817880",
      "metadata": {
        "id": "89817880"
      },
      "source": [
        "- 입력 데이터와 타겟 데이터를 장치에 적용하는 과정을 실습합니다. 이는 PyTorch에서 효율적인 계산을 위한 필수적인 단계입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "134a76ab",
      "metadata": {
        "id": "134a76ab"
      },
      "source": [
        "## 06-023 모델 학습 및 손실 계산\n",
        "- 이 실습에서는 정의한 텍스트 분류기 모델을 학습시키고 손실을 계산하는 과정을 구현합니다. BCELoss를 손실 함수로 사용하고, Adam 옵티마이저를 통해 모델의 파라미터를 업데이트합니다. 지정된 최대 에폭 수만큼 모델을 학습시키며, 주기적으로 손실 값을 출력합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19c26517",
      "metadata": {
        "id": "19c26517"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.BCELoss()  # 손실 함수\n",
        "optimizer = optim.Adam(model.parameters())  # 최적화 도구(optimizer)\n",
        "\n",
        "epochs = 30000  # 최대 에폭 지정\n",
        "results = {'cost':[]}\n",
        "\n",
        "model.train()  # 학습 모드 설정\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    h = model(x)  # 예측 값 생성(추론)\n",
        "    loss = loss_fn(h, y)  # 손실 계산\n",
        "\n",
        "    optimizer.zero_grad()  # 미분 값 초기화\n",
        "    loss.backward()  # 역전파(미분 계산)\n",
        "    optimizer.step()  # 업데이트 진행\n",
        "\n",
        "    results['cost'].append(loss.item())\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f'epoch: {epoch:4d}, cost: {results[\"cost\"][-1]:.10f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2dffbd9",
      "metadata": {
        "id": "f2dffbd9"
      },
      "source": [
        "- 모델을 학습시키고 손실을 계산하여 업데이트하는 과정을 실습합니다. 학습 과정의 손실 변화를 모니터링하는 것은 모델의 성능을 이해하는 데 중요합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d8f0b7",
      "metadata": {
        "id": "f4d8f0b7"
      },
      "source": [
        "## 06-024 예측 값을 클래스로 변환\n",
        "- 이 실습에서는 모델의 예측 값을 시그모이드 결과를 기반으로 클래스로 변환하는 방법을 학습합니다. h.view(-1)로 예측 결과를 평탄화한 후, 0.5를 기준으로 이진 클래스로 변환합니다. 실제 값과 예측 값을 출력하여 모델의 성능을 평가합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab65da64",
      "metadata": {
        "id": "ab65da64"
      },
      "outputs": [],
      "source": [
        "# 예측 값(시그모이드 값)을 클래스로 변환\n",
        "pred = (h.reshape(-1).detach().cpu() > 0.5).to(torch.float32)\n",
        "\n",
        "print(f'실제 값: {y.reshape(-1)}')\n",
        "print(f'예측 값: {pred}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81cf6d11",
      "metadata": {
        "id": "81cf6d11"
      },
      "source": [
        "- 모델의 예측 값을 클래스 형태로 변환하고, 실제 값과 비교하여 출력하는 과정을 실습합니다. 이는 모델의 예측 정확도를 확인하는 데 중요합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d7ef944",
      "metadata": {
        "id": "9d7ef944"
      },
      "source": [
        "## 연습문제-06-001 10개 문서 유형 분류를 위한 모델 정의 (Module 방식)\n",
        "- 이 실습에서는 문서 유형 10개를 분류하기 위한 신경망 모델을 Module 방식으로 정의합니다. 이 모델은 입력된 문서 데이터를 임베딩 레이어와 LSTM 계층을 거쳐 처리한 후, 10개의 출력값을 가지는 완전 연결층을 통해 각 문서가 어느 유형에 속하는지 예측합니다. 활성화 함수는 적용되지 않으며, 출력값을 통해 각 클래스에 대한 로짓 값을 반환합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e6a4834",
      "metadata": {
        "id": "3e6a4834"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# DocumentClassifier 모델 정의\n",
        "class DocumentClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, num_class=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1. Embedding 계층: 입력된 단어를 고차원 벡터로 변환합니다.\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)  # vocab_size: 단어 사전 크기, embed_dim: 임베딩 차원 수\n",
        "\n",
        "        # 2. LSTM 계층: 순차적 데이터를 처리하는 LSTM 계층입니다.\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_size, batch_first=True)  # embed_dim 크기의 입력을 받아 hidden_size 크기의 출력을 반환\n",
        "\n",
        "        # 3. Fully Connected Layer (FC): LSTM의 출력을 사용해 문서 유형을 분류하는 계층입니다.\n",
        "        self.fc = nn.Linear(hidden_size, num_class)  # hidden_size에서 10개의 문서 유형으로 분류\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 4. 입력 데이터 임베딩 변환\n",
        "        out = self.embedding(x)\n",
        "\n",
        "        # 5. LSTM 계층을 통과시켜 순차적 특성 학습\n",
        "        out, _ = self.lstm(out)\n",
        "\n",
        "        # 6. LSTM의 마지막 타임스텝의 출력을 사용해 FC 계층에 전달\n",
        "        out = self.fc(out[:, -1, :])  # LSTM의 마지막 출력 사용\n",
        "\n",
        "        # 7. 활성화 함수 없이 10개의 출력값 반환\n",
        "        return out  # 최종 출력값: (배치 크기, 10개의 문서 유형)\n",
        "\n",
        "model = DocumentClassifier(vocab_size=10000, embed_dim=128, hidden_size=256)\n",
        "model(torch.randint(0, 10000, (100, 20))).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "124567e0",
      "metadata": {
        "id": "124567e0"
      },
      "source": [
        "- 이 실습에서는 PyTorch의 Module 방식을 사용해 문서 유형 10개를 분류하는 모델을 정의합니다. 이 모델은 LSTM을 통해 문서의 순차적 특성을 학습하고, 완전 연결층을 사용하여 10개의 범주로 문서를 분류합니다.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}